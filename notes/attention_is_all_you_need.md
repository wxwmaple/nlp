# Attention is all you need

## (Summary)

## (Research Objective)

构建新的网络架构Transformer，并避免任何的循环层，提高并行能力。

## (Methods)

## (Evaluation)

## (Conclusion)

## (Notes--optional)

- attention mechanism？
- 新网络架构Transformer：只基于Attention机制，无CNN/RNN
- BLEU：一种机器翻译的效果指标
- 序列建模：LSTM和RNN的天下（曾经）
